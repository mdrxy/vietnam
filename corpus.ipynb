{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93791b71-f2c7-4063-84e9-278470de93f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "here() starts at /home/mdaugher/DCS-2500/vietnam\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set path to articles folder\n",
    "library(here)\n",
    "folder_path <- here(\"articles\")\n",
    "setwd(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b034a389-bef3-4def-9c3a-6d3943e2387e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of .txt files to create corpus from\n",
    "file_list <- list.files(pattern = \"\\\\.txt$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb17b013-e33e-4f8d-a4e5-411e13dabef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in file content by space character\n",
    "read_file_content <- function(file) {\n",
    "    file_content <- suppressWarnings(readLines(file))\n",
    "    file_content <- paste(file_content, collapse = \" \")\n",
    "    return(file_content)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d54c4e56-257d-4905-9c44-5b73af5362b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the title\n",
    "extract_title <- function(file_content) {\n",
    "    title <- sub(\"@BODY=.*\", \"\", file_content)\n",
    "    title <- sub(\"@TITLE=\", \"\", title) \n",
    "    title <- gsub(\"\\\\s+\", \" \", gsub(\"(^\\\\s+|\\\\s+$)\", \"\", title)) # remove bizarre spaces\n",
    "    return(title)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b548bb78-9501-40ff-95da-f53ee33debe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract body text\n",
    "extract_body_text <- function(file) {\n",
    "    body <- sub(\".*@BODY=\", \"\", file)\n",
    "    return(body)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24d1d2cc-c9d9-4a6d-96ce-bbabeaa01214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation/special characters, a.k.a., ONLY KEEP LETTERS (and spaces)\n",
    "keep_letters <- function(body) {\n",
    "    body_letters_only <- gsub(\"-\", \" \", body_lowercase) # replaces \"-\" with \" \"\n",
    "    body_letters_only <- gsub(\"[^[:alpha:][:space:]]\", \"\", body_letters_only)\n",
    "    body_letters_only <- gsub(\"\\\\s+\", \" \", body_letters_only) # remove multiple sequential spaces\n",
    "    return(body_letters_only)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38d7e793-ccfd-4ef5-a129-125370f03868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the words (tokenize)\n",
    "tokenize <- function(body_cleaned) {\n",
    "    body_words <- unlist(strsplit(body_letters_only, \" \"))\n",
    "    return(body_words)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c08df71b-ae72-46ec-b993-0e17b11e8787",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidytext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65eba62f-180e-49f1-981c-14e82eb2fe1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 1149 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>word</th><th scope=col>lexicon</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>a          </td><td>SMART</td></tr>\n",
       "\t<tr><td>a's        </td><td>SMART</td></tr>\n",
       "\t<tr><td>able       </td><td>SMART</td></tr>\n",
       "\t<tr><td>about      </td><td>SMART</td></tr>\n",
       "\t<tr><td>above      </td><td>SMART</td></tr>\n",
       "\t<tr><td>according  </td><td>SMART</td></tr>\n",
       "\t<tr><td>accordingly</td><td>SMART</td></tr>\n",
       "\t<tr><td>across     </td><td>SMART</td></tr>\n",
       "\t<tr><td>actually   </td><td>SMART</td></tr>\n",
       "\t<tr><td>after      </td><td>SMART</td></tr>\n",
       "\t<tr><td>afterwards </td><td>SMART</td></tr>\n",
       "\t<tr><td>again      </td><td>SMART</td></tr>\n",
       "\t<tr><td>against    </td><td>SMART</td></tr>\n",
       "\t<tr><td>ain't      </td><td>SMART</td></tr>\n",
       "\t<tr><td>all        </td><td>SMART</td></tr>\n",
       "\t<tr><td>allow      </td><td>SMART</td></tr>\n",
       "\t<tr><td>allows     </td><td>SMART</td></tr>\n",
       "\t<tr><td>almost     </td><td>SMART</td></tr>\n",
       "\t<tr><td>alone      </td><td>SMART</td></tr>\n",
       "\t<tr><td>along      </td><td>SMART</td></tr>\n",
       "\t<tr><td>already    </td><td>SMART</td></tr>\n",
       "\t<tr><td>also       </td><td>SMART</td></tr>\n",
       "\t<tr><td>although   </td><td>SMART</td></tr>\n",
       "\t<tr><td>always     </td><td>SMART</td></tr>\n",
       "\t<tr><td>am         </td><td>SMART</td></tr>\n",
       "\t<tr><td>among      </td><td>SMART</td></tr>\n",
       "\t<tr><td>amongst    </td><td>SMART</td></tr>\n",
       "\t<tr><td>an         </td><td>SMART</td></tr>\n",
       "\t<tr><td>and        </td><td>SMART</td></tr>\n",
       "\t<tr><td>another    </td><td>SMART</td></tr>\n",
       "\t<tr><td>⋮</td><td>⋮</td></tr>\n",
       "\t<tr><td>went    </td><td>onix</td></tr>\n",
       "\t<tr><td>were    </td><td>onix</td></tr>\n",
       "\t<tr><td>what    </td><td>onix</td></tr>\n",
       "\t<tr><td>when    </td><td>onix</td></tr>\n",
       "\t<tr><td>where   </td><td>onix</td></tr>\n",
       "\t<tr><td>whether </td><td>onix</td></tr>\n",
       "\t<tr><td>which   </td><td>onix</td></tr>\n",
       "\t<tr><td>while   </td><td>onix</td></tr>\n",
       "\t<tr><td>who     </td><td>onix</td></tr>\n",
       "\t<tr><td>whole   </td><td>onix</td></tr>\n",
       "\t<tr><td>whose   </td><td>onix</td></tr>\n",
       "\t<tr><td>why     </td><td>onix</td></tr>\n",
       "\t<tr><td>will    </td><td>onix</td></tr>\n",
       "\t<tr><td>with    </td><td>onix</td></tr>\n",
       "\t<tr><td>within  </td><td>onix</td></tr>\n",
       "\t<tr><td>without </td><td>onix</td></tr>\n",
       "\t<tr><td>work    </td><td>onix</td></tr>\n",
       "\t<tr><td>worked  </td><td>onix</td></tr>\n",
       "\t<tr><td>working </td><td>onix</td></tr>\n",
       "\t<tr><td>works   </td><td>onix</td></tr>\n",
       "\t<tr><td>would   </td><td>onix</td></tr>\n",
       "\t<tr><td>year    </td><td>onix</td></tr>\n",
       "\t<tr><td>years   </td><td>onix</td></tr>\n",
       "\t<tr><td>yet     </td><td>onix</td></tr>\n",
       "\t<tr><td>you     </td><td>onix</td></tr>\n",
       "\t<tr><td>young   </td><td>onix</td></tr>\n",
       "\t<tr><td>younger </td><td>onix</td></tr>\n",
       "\t<tr><td>youngest</td><td>onix</td></tr>\n",
       "\t<tr><td>your    </td><td>onix</td></tr>\n",
       "\t<tr><td>yours   </td><td>onix</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 1149 × 2\n",
       "\\begin{tabular}{ll}\n",
       " word & lexicon\\\\\n",
       " <chr> & <chr>\\\\\n",
       "\\hline\n",
       "\t a           & SMART\\\\\n",
       "\t a's         & SMART\\\\\n",
       "\t able        & SMART\\\\\n",
       "\t about       & SMART\\\\\n",
       "\t above       & SMART\\\\\n",
       "\t according   & SMART\\\\\n",
       "\t accordingly & SMART\\\\\n",
       "\t across      & SMART\\\\\n",
       "\t actually    & SMART\\\\\n",
       "\t after       & SMART\\\\\n",
       "\t afterwards  & SMART\\\\\n",
       "\t again       & SMART\\\\\n",
       "\t against     & SMART\\\\\n",
       "\t ain't       & SMART\\\\\n",
       "\t all         & SMART\\\\\n",
       "\t allow       & SMART\\\\\n",
       "\t allows      & SMART\\\\\n",
       "\t almost      & SMART\\\\\n",
       "\t alone       & SMART\\\\\n",
       "\t along       & SMART\\\\\n",
       "\t already     & SMART\\\\\n",
       "\t also        & SMART\\\\\n",
       "\t although    & SMART\\\\\n",
       "\t always      & SMART\\\\\n",
       "\t am          & SMART\\\\\n",
       "\t among       & SMART\\\\\n",
       "\t amongst     & SMART\\\\\n",
       "\t an          & SMART\\\\\n",
       "\t and         & SMART\\\\\n",
       "\t another     & SMART\\\\\n",
       "\t ⋮ & ⋮\\\\\n",
       "\t went     & onix\\\\\n",
       "\t were     & onix\\\\\n",
       "\t what     & onix\\\\\n",
       "\t when     & onix\\\\\n",
       "\t where    & onix\\\\\n",
       "\t whether  & onix\\\\\n",
       "\t which    & onix\\\\\n",
       "\t while    & onix\\\\\n",
       "\t who      & onix\\\\\n",
       "\t whole    & onix\\\\\n",
       "\t whose    & onix\\\\\n",
       "\t why      & onix\\\\\n",
       "\t will     & onix\\\\\n",
       "\t with     & onix\\\\\n",
       "\t within   & onix\\\\\n",
       "\t without  & onix\\\\\n",
       "\t work     & onix\\\\\n",
       "\t worked   & onix\\\\\n",
       "\t working  & onix\\\\\n",
       "\t works    & onix\\\\\n",
       "\t would    & onix\\\\\n",
       "\t year     & onix\\\\\n",
       "\t years    & onix\\\\\n",
       "\t yet      & onix\\\\\n",
       "\t you      & onix\\\\\n",
       "\t young    & onix\\\\\n",
       "\t younger  & onix\\\\\n",
       "\t youngest & onix\\\\\n",
       "\t your     & onix\\\\\n",
       "\t yours    & onix\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 1149 × 2\n",
       "\n",
       "| word &lt;chr&gt; | lexicon &lt;chr&gt; |\n",
       "|---|---|\n",
       "| a           | SMART |\n",
       "| a's         | SMART |\n",
       "| able        | SMART |\n",
       "| about       | SMART |\n",
       "| above       | SMART |\n",
       "| according   | SMART |\n",
       "| accordingly | SMART |\n",
       "| across      | SMART |\n",
       "| actually    | SMART |\n",
       "| after       | SMART |\n",
       "| afterwards  | SMART |\n",
       "| again       | SMART |\n",
       "| against     | SMART |\n",
       "| ain't       | SMART |\n",
       "| all         | SMART |\n",
       "| allow       | SMART |\n",
       "| allows      | SMART |\n",
       "| almost      | SMART |\n",
       "| alone       | SMART |\n",
       "| along       | SMART |\n",
       "| already     | SMART |\n",
       "| also        | SMART |\n",
       "| although    | SMART |\n",
       "| always      | SMART |\n",
       "| am          | SMART |\n",
       "| among       | SMART |\n",
       "| amongst     | SMART |\n",
       "| an          | SMART |\n",
       "| and         | SMART |\n",
       "| another     | SMART |\n",
       "| ⋮ | ⋮ |\n",
       "| went     | onix |\n",
       "| were     | onix |\n",
       "| what     | onix |\n",
       "| when     | onix |\n",
       "| where    | onix |\n",
       "| whether  | onix |\n",
       "| which    | onix |\n",
       "| while    | onix |\n",
       "| who      | onix |\n",
       "| whole    | onix |\n",
       "| whose    | onix |\n",
       "| why      | onix |\n",
       "| will     | onix |\n",
       "| with     | onix |\n",
       "| within   | onix |\n",
       "| without  | onix |\n",
       "| work     | onix |\n",
       "| worked   | onix |\n",
       "| working  | onix |\n",
       "| works    | onix |\n",
       "| would    | onix |\n",
       "| year     | onix |\n",
       "| years    | onix |\n",
       "| yet      | onix |\n",
       "| you      | onix |\n",
       "| young    | onix |\n",
       "| younger  | onix |\n",
       "| youngest | onix |\n",
       "| your     | onix |\n",
       "| yours    | onix |\n",
       "\n"
      ],
      "text/plain": [
       "     word        lexicon\n",
       "1    a           SMART  \n",
       "2    a's         SMART  \n",
       "3    able        SMART  \n",
       "4    about       SMART  \n",
       "5    above       SMART  \n",
       "6    according   SMART  \n",
       "7    accordingly SMART  \n",
       "8    across      SMART  \n",
       "9    actually    SMART  \n",
       "10   after       SMART  \n",
       "11   afterwards  SMART  \n",
       "12   again       SMART  \n",
       "13   against     SMART  \n",
       "14   ain't       SMART  \n",
       "15   all         SMART  \n",
       "16   allow       SMART  \n",
       "17   allows      SMART  \n",
       "18   almost      SMART  \n",
       "19   alone       SMART  \n",
       "20   along       SMART  \n",
       "21   already     SMART  \n",
       "22   also        SMART  \n",
       "23   although    SMART  \n",
       "24   always      SMART  \n",
       "25   am          SMART  \n",
       "26   among       SMART  \n",
       "27   amongst     SMART  \n",
       "28   an          SMART  \n",
       "29   and         SMART  \n",
       "30   another     SMART  \n",
       "⋮    ⋮           ⋮      \n",
       "1120 went        onix   \n",
       "1121 were        onix   \n",
       "1122 what        onix   \n",
       "1123 when        onix   \n",
       "1124 where       onix   \n",
       "1125 whether     onix   \n",
       "1126 which       onix   \n",
       "1127 while       onix   \n",
       "1128 who         onix   \n",
       "1129 whole       onix   \n",
       "1130 whose       onix   \n",
       "1131 why         onix   \n",
       "1132 will        onix   \n",
       "1133 with        onix   \n",
       "1134 within      onix   \n",
       "1135 without     onix   \n",
       "1136 work        onix   \n",
       "1137 worked      onix   \n",
       "1138 working     onix   \n",
       "1139 works       onix   \n",
       "1140 would       onix   \n",
       "1141 year        onix   \n",
       "1142 years       onix   \n",
       "1143 yet         onix   \n",
       "1144 you         onix   \n",
       "1145 young       onix   \n",
       "1146 younger     onix   \n",
       "1147 youngest    onix   \n",
       "1148 your        onix   \n",
       "1149 yours       onix   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0927c8c-742a-457b-aab2-85198b0bca55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words from body\n",
    "remove_stop_words <- function(body_tokenized) {\n",
    "    body_stop_words_removed <- body_words[!body_words %in% stopwords(\"english\")]\n",
    "    return(body_stop_words_removed)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0ef06b2-f2a4-4954-bb2a-e1dab4971495",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in stopwords(\"english\"): could not find function \"stopwords\"\n",
     "output_type": "error",
     "traceback": [
      "Error in stopwords(\"english\"): could not find function \"stopwords\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "stopwords(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b004db3-a18a-46a5-8911-6c8af561b8b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'092_04-26-1962_EXCERPTS.DEVELOP.BURNHAMS.VIEWS.ON.WORLD.SITUATION.txt'"
      ],
      "text/latex": [
       "'092\\_04-26-1962\\_EXCERPTS.DEVELOP.BURNHAMS.VIEWS.ON.WORLD.SITUATION.txt'"
      ],
      "text/markdown": [
       "'092_04-26-1962_EXCERPTS.DEVELOP.BURNHAMS.VIEWS.ON.WORLD.SITUATION.txt'"
      ],
      "text/plain": [
       "[1] \"092_04-26-1962_EXCERPTS.DEVELOP.BURNHAMS.VIEWS.ON.WORLD.SITUATION.txt\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76c37ebe-668b-4d9d-af98-f237aabf7f5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in strsplit(body_letters_only, \" \"): object 'body_letters_only' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in strsplit(body_letters_only, \" \"): object 'body_letters_only' not found\nTraceback:\n",
      "1. tokenize(body_cleaned)",
      "2. unlist(strsplit(body_letters_only, \" \"))   # at line 3 of file <text>",
      "3. strsplit(body_letters_only, \" \")"
     ]
    }
   ],
   "source": [
    "# Get data from a file\n",
    "\n",
    "i <- 1\n",
    "ingest <- file_list[i]\n",
    "\n",
    "file_content <- read_file_content(ingest)\n",
    "\n",
    "# Get title\n",
    "title <- extract_title(file_content)\n",
    "\n",
    "# Get body\n",
    "body <- extract_body_text(file_content)\n",
    "body_lowercase <- tolower(body) # Make the body text lowercase\n",
    "body_cleaned <- keep_letters(body_lowercase)\n",
    "body_tokenized <- tokenize(body_cleaned)\n",
    "body_stop_words_removed <- remove_stop_words(body_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df5059f-d553-4d76-9e2a-2f89659ef285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the issue from a 3 digit format, e.g. 096 for issue 96, 112 for 112, etc.\n",
    "issue <- strsplit(ingest, \"_\")[[1]][1]\n",
    "if (grepl(\"^0\", issue)) {\n",
    "  issue <- substring(issue, 2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25924ff7-7ad5-448e-9ac1-e8d85db69574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the date from the format mm-dd-yyyy\n",
    "date <- strsplit(ingest, \"_\")[[1]][2]\n",
    "date <- as.Date(date, format = \"%m-%d-%Y\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R 4.2",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
